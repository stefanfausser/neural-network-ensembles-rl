# seed = 1201617342

# Number of hidden layers
nrHiddenLayers = 1

# Number of neurons in hidden layer
# m will be overwritten !
m = 1
h0 = 10
# h1 = 10
# h1 = 10
# h1 = 5
n = 1

# Number of maximum iterations in error backpropagation algorithm
maxIterations = 1

# learning rate ("big" value above 0.5 if momentumterm is used)
eta1 = 0.1
eta2 = 0.1

# minimum error rate
epsilon = 0.000001
# epsilon = 0.001

# weights are randomly initialized between -a and +a
# default is a = 2/m if a is not defined
a = 0.2
aOut = 0.2
weightNormalizedInitialization = 0
thresholdZeroInitialization = 0

# currently following transfer function types are supported:
# 0 = logistic function
# 1 = fermi function (see parameter beta)
# 2 = tangens hyperbolicus (preferred)
# 3 = linear (only appropriate for output layer)
transFktTypeHidden = 2
transFktTypeOutput = 3
hasThresholdOutput = 0

# parameter in fermi function
beta = 0.5

# parameter for resilient and or supersab
#eta_pos = 1.3
eta_neg = 0.5
eta_pos = 1.2
#eta_neg = 0.5
eta_start = 0.0125
eta_max = 50.0
eta_min = 0.000001

# parameter for quickprop
beta_max = 1.2

# parameter for batch learning with momentumterm
alpha = 0.5

# currently following training modes are supported:
# 0 = Online
# 1 = Batch
# 2 = Batch learning with Momentumterm
# 3 = SuperSAB
# 4 = Resilient (RPROP-)
# 5 = Quickprop
# 6 = RPROP+
trainingMode = 8

# 0 = mlp verbose output off
# 1 = mlp verbose output on
verboseOutput = 0
